{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c7acdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HCMUS_ComputerScience\\ComputationalThinking\\TeamProject\\reactProject\\CLIP_Model\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Load a pre-trained CLIP model\n",
    "model = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84811073",
   "metadata": {},
   "outputs": [],
   "source": [
    "## declare constant and necessary variables\n",
    "DB_path = \"../DataCollector/result/places.db\"\n",
    "DB_name = \"places\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368286b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "from typing import List\n",
    "import torch\n",
    "\n",
    "def parseList(image_list):\n",
    "    print(type(image_list))\n",
    "    return json.loads(image_list)\n",
    "\n",
    "def getImages(id):\n",
    "    \"Return a list of PIL images\"\n",
    "    conn = sqlite3.connect(DB_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT images FROM {DB_name} WHERE rowid = ?\", (id,))\n",
    "    image_url = cursor.fetchone()[0]\n",
    "    image_url = parseList(image_url)\n",
    "    pil_image = []\n",
    "    for url in image_url:\n",
    "        print(url)\n",
    "        pil_image.append(Image.open(requests.get(url, stream=True).raw))\n",
    "\n",
    "    return pil_image\n",
    "\n",
    "def embedImageList(images):\n",
    "    if len(images) == 0:\n",
    "        return torch.zeros(1, 512)\n",
    "    print(\"len(images) = \",len(images))\n",
    "    encoding = [model.encode(image) for image in images]\n",
    "    print(type(encoding[0]))\n",
    "    # list of numpy.ndarray\n",
    "    return sum(encoding) / len(encoding)\n",
    "    \n",
    "\n",
    "def embedText(text):\n",
    "    return model.encode(text)\n",
    "\n",
    "def getSimilarity(imageList, text):\n",
    "    image_emb = embedImageList(imageList)\n",
    "    text_emb = embedText(text)\n",
    "    return util.cos_sim(image_emb, text_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b97494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "https://lh3.googleusercontent.com/p/AF1QipOSisTfpcYNbHV-0X3CB0E7pedEkh10avYId7eI=s0\n",
      "https://lh3.googleusercontent.com/geougc-cs/AMBA38t2Kmr5_XJSv2PmDO10nabcToVMxqXZwW_M3PM9su_8PO1ED7uHBVqxnIGzYii6adp4DKOc07hYToYMGDCTK0A3sAnVZ0OcbUO7mh2w_5YBiC8MdqHRYBeFKFKBpXXethGqvS89=s0\n",
      "https://lh3.googleusercontent.com/geougc-cs/AMBA38v8qd5Fo9KkbRzRKrYOOmP0JZxnFWPrjFUB2mbsDD04wT1pUBB01TM531RbG3_ZpfpUGoJgt2bvWrR0k5fFq7jkd3sp2m60IGig0JZJXf_wFPc2ANdfgFi1GH8-L_Wlg3dm-r9TpA=s0\n",
      "[[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1440 at 0x288D4B52910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3024x4032 at 0x288D4B3CB50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x288D4A0E710>]]\n",
      "len(images) =  3\n",
      "<class 'numpy.ndarray'>\n",
      "[tensor([[0.2461]])]\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Đồ ăn ngon\"\n",
    "sample_images = [getImages(i) for i in range(2, 3)]\n",
    "\n",
    "print(sample_images)\n",
    "\n",
    "\n",
    "# my_embeddings = model.encode(sample_text)\n",
    "print([getSimilarity(image, sample_text) for image in sample_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8e91e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index loaded successfully from test_images.bin\n",
      "Index type: <class 'faiss.swigfaiss_avx2.IndexFlatL2'>\n",
      "Total number of vectors in the index: 10\n",
      "Vector ID 0 first value: [-0.06810567  0.01319423  0.34572196 -0.15017727  0.56712866 -0.2609901\n",
      " -0.11243334  0.19935876  0.6692451   0.04950246]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 1 first value: [-0.05430037  0.08203101  0.32165593 -0.00292639  0.6371502  -0.40463907\n",
      "  0.13588804  0.19987547  0.43858612  0.33127224]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 2 first value: [-0.7186376  -0.06840184  0.16661792  0.4748946   0.07506506 -0.295602\n",
      "  0.5527995   0.5271174  -0.2700316   0.43091565]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 3 first value: [-0.4066123  -0.24284181  0.3125778   0.3667134   0.17926046 -0.46689886\n",
      "  0.17147157 -0.09994288 -0.648865    0.29288262]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 4 first value: [-0.599694   -0.00558543  0.3761969   0.46527785  0.27332696 -0.48122376\n",
      "  0.2110529  -0.38230103 -0.47607696  0.15118171]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 5 first value: [-0.3777513   0.2839992  -0.2602271   0.32835767  0.344704   -0.12381932\n",
      "  0.2778062   0.1658559   0.3031289  -0.1898435 ]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 6 first value: [-0.6931855   0.27245504 -0.15728053  0.6793456   0.15226412 -0.10410348\n",
      " -0.12156875 -0.02366602  0.28264123 -0.21380341]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 7 first value: [ 0.15162054  0.3083256  -0.7084624  -0.3996725   0.10547259  0.28789872\n",
      "  0.19530782  0.64592105  0.698459    0.28624833]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 8 first value: [-0.15784155  0.19825391  0.11513114  0.0941451  -0.03182487  0.1883194\n",
      " -0.41789472  0.40151906  0.264386    0.36822364]\n",
      "Shape of the vector: (512,)\n",
      "Vector ID 9 first value: [-0.2909539   0.07930981 -0.18869022  0.41001633  0.13575365 -0.01307261\n",
      "  0.04196743  0.2929058   0.504314    0.17237544]\n",
      "Shape of the vector: (512,)\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Define the path to your .bin file\n",
    "index_file_path = \"test_images.bin\"\n",
    "\n",
    "# Load the index from the file\n",
    "try:\n",
    "    index = faiss.read_index(index_file_path)\n",
    "    print(f\"Index loaded successfully from {index_file_path}\")\n",
    "    print(f\"Index type: {type(index)}\")\n",
    "    print(f\"Total number of vectors in the index: {index.ntotal}\")\n",
    "    for vector_id in range(10):\n",
    "        # Returns a numpy array with shape (dimension,)\n",
    "        vec = index.reconstruct(vector_id) \n",
    "\n",
    "        print(f\"Vector ID {vector_id} first value: {vec[:10]}\")\n",
    "        print(f\"Shape of the vector: {vec.shape}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error loading index: {e}\")\n",
    "    print(\"Ensure the file path is correct and the file is a valid FAISS index file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
